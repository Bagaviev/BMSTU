{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid requirement: '##'\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1654, in parseString\n",
      "    raise exc\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1644, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3417, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3739, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3400, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1406, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2711, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_internal\\req\\constructors.py\", line 253, in install_req_from_line\n",
      "    req = Requirement(req)\n",
      "  File \"d:\\anaconda\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 96, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8], e.msg\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Parse error at \"'##'\": Expected W:(abcd...)\n",
      "\n",
      "You are using pip version 18.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install dask --upgrade ## ugly error with core.computation in pandas! this solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-ccbc55d1b47f>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\bulat\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-ccbc55d1b47f>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR,one_hot = True)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]), dtype = tf.float32)\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W) + b\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.51% \n"
     ]
    }
   ],
   "source": [
    "with tf.Session () as sess:\n",
    "# Train\n",
    "    sess.run(tf.global_variables_initializer ())\n",
    "    for i in range ( NUM_STEPS ):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x , y_true: batch_y})\n",
    "    ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "print (\"Accuracy {:.4}% \".format(ans * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR,one_hot = True)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]), dtype = tf.float32)\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = 1/(1 + tf.exp(tf.matmul(x, W) + b))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "[[4.5347738e-04 9.9574226e-01 2.4904650e-02 5.3015947e-02 8.6976914e-03\n",
      "  3.9674263e-03 3.7547359e-03 1.0760186e-01 6.6011816e-02 3.7191041e-02]]\n",
      "[1]\n",
      "Accuracy 88.73% \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY3UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27992ae1748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUMBER_TO_TEST = 5  #from 0 to 9999\n",
    "\n",
    "with tf.Session () as sess:\n",
    "    sess.run(tf.global_variables_initializer ())\n",
    "    for i in range (NUM_STEPS):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x , y_true: batch_y})\n",
    "    ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "    \n",
    "    print(data.test.images[NUMBER_TO_TEST,:][None,:].shape)\n",
    "    #My code\n",
    "    output_pr = sess.run(y_pred, feed_dict={x: data.test.images[NUMBER_TO_TEST,:][None,:]})\n",
    "    \n",
    "    output_pos =sess.run(tf.argmax(output_pr,1), feed_dict={x: data.test.images[NUMBER_TO_TEST,:][None,:]})\n",
    "    #output_pos = sess.run(tf.argmax(y_pred, 1), feed_dict={x: data.test.images})\n",
    "    print(output_pr)#[NUMBER_TO_TEST])\n",
    "    print(output_pos)#[NUMBER_TO_TEST])\n",
    "    #My code ended\n",
    "    \n",
    "print (\"Accuracy {:.4}% \".format(ans * 100))\n",
    "   \n",
    "    \n",
    "#My code \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plotData = data.test.images[NUMBER_TO_TEST]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(data.test.labels[NUMBER_TO_TEST])\n",
    "#My code ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural models \n",
    "#### (can be done with GPU but need extra steps) - accuracy higher then previous!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = 60\n",
    "L2 = 30\n",
    "L3 = 10\n",
    "\n",
    "DATA_DIR = 'tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f60500d15d20>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-3-f60500d15d20>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR, one_hot = True)\n",
    "x = tf.placeholder(tf.float32 , [None, 784])\n",
    "l1 = tf.layers.dense(x, L1, activation = tf.nn.relu, use_bias = True)\n",
    "l2 = tf.layers.dense(l1, L2, activation = tf.nn.relu, use_bias = True)\n",
    "y_pred = tf.layers.dense(l2, L3, activation = tf.nn.relu, use_bias = True)\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.65% \n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time #slow learn\n",
    "with tf.Session () as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range (NUM_STEPS):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x, y_true : batch_y})\n",
    "        ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "print(\"Accuracy: {:.4}% \".format(ans*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        2.4245925 0.        0.        0.        0.\n",
      " 0.        4.9801817 0.       ]\n",
      "8\n",
      "Accuracy 95.16% \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD4JJREFUeJzt3X+QVfV5x/HPs7iw/FADUexGiVhF\nxDEJ2A3aklobqkVjokyiIzM1pGMliT/aNNoUqVP9o+1QY6ImauqqVMwYMVM12oxt1K2JMSboilZE\nrFKKiu4sEhQICgL79I89ZFbd873rvefec5fn/Zph7r3nOeeexzt+9tx7v+fcr7m7AMTTUnYDAMpB\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBLVPI3c20kZ5m8Y2cpdAKNu1Te/4DhvKujWF38zm\nSLpW0ghJN7v74tT6bRqr42x2LbsEkLDcu4a8btVv+81shKTrJZ0i6WhJ88zs6GqfD0Bj1fKZf6ak\nNe6+1t3fkbRM0unFtAWg3moJ/8GSXhnweH227F3MbIGZdZtZ907tqGF3AIpUS/gH+1LhfdcHu3un\nu3e4e0erRtWwOwBFqiX86yVNGvD4EEmv1dYOgEapJfxPSJpiZoeZ2UhJZ0u6r5i2ANRb1UN97r7L\nzC6U9BP1D/UtcfdVhXUGoK5qGud39/sl3V9QLwAaiNN7gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqoVN0I57/\nW/bx3NrR7b3Jbe864j+S9WvfOCJZv3XJnNzapDvXJbfd9ereP/8MR34gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCMrcvfqNzdZJ2ippt6Rd7t6RWn8/m+DH2eyq94fGW3/pHyTr5/1ZepLmr37oxdxaS4nH\nnllPn52sj/9Mft/NbLl3aYtvsqGsW8RJPn/s7hsLeB4ADcTbfiCoWsPvkh4wsyfNbEERDQFojFrf\n9s9y99fMbKKkB83seXd/ZOAK2R+FBZLUpjE17g5AUWo68rv7a9ntBkn3SJo5yDqd7t7h7h2tGlXL\n7gAUqOrwm9lYM9t3z31JJ0t6tqjGANRXLW/7D5J0j5nteZ4fuPt/FtIVgLqrOvzuvlbSJwrsBVWy\nUfkfp9b804zktued3JWsL/jQVcn6zZs/lqynxvIX9SZPC1H7yM3J+kXjqx+Lf+vnBybr4zU8x/k/\nCIb6gKAIPxAU4QeCIvxAUIQfCIrwA0Hx093DQMsxRyXru67dlltbfdT1Ne172s/OT9annJceEnvg\n2BNyayPXvZ7c9plbD07WKw319e5+O7d2SNfW5LbVX+g+fHDkB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgGOdvAi1j0j9vtnFxX7L+2FE/KrKdd9n/p6OT9b5t+ecYSFLryrW5teeuPDK57UNHXJ2s37J5\narJ++2Wn5dbGPf9cclvG+QHstQg/EBThB4Ii/EBQhB8IivADQRF+ICjG+ZvBkZOT5cdmfL/qp+5T\n+hyBO7amr5k/oPOX6ef/w/RPg3/uxodya3/f9l/Jbb9w5TeSdVWYiHri3Y/l1tKvSgwc+YGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gqIrj/Ga2RNJpkja4+zHZsgmS7pQ0WdI6SWe5+xv1a3Pvtu3Qccn6\n5r7tyfpOz7/6fO6llyS33f/2XyXrLdOPTtb/bum/Juu/P2p3bm3az85Nbnv49fnj9KjdUI78t0qa\n855lCyV1ufsUSV3ZYwDDSMXwu/sjkja9Z/HpkpZm95dKOqPgvgDUWbWf+Q9y9x5Jym4nFtcSgEao\n+7n9ZrZA0gJJalP6t+oANE61R/5eM2uXpOx2Q96K7t7p7h3u3tGqUVXuDkDRqg3/fZLmZ/fnS7q3\nmHYANErF8JvZHZJ+KWmqma03s3MlLZZ0kpm9KOmk7DGAYaTiZ353n5dTml1wL2GNvvfxZP2fL/9U\nsn7ZxPzx8Lcnpv++7/tH6evxT7nh4WT9Y61vJevHPv4XubXDbqxwQT7qijP8gKAIPxAU4QeCIvxA\nUIQfCIrwA0Hx093DwK/+YWay/tQ3/zu31n3Jd2vad0uF38ee9v2Lk/XDFqZ/+hvl4cgPBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0Exzj8MjH0lfdnsyu2Tcmuz2tYW3c67jO7lstzhiiM/EBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwTFOH8DjDjgw8n6xtOOTNbPX3hXsr69rzW3NrXrvOS2N81amqzPHp0/xbYk\nrbjkumT9qIMuyK0dsWxzctu+p59L1lEbjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EJS5e3oFsyWS\nTpO0wd2PyZZdIek8Sa9nqy1y9/sr7Ww/m+DH2d43s7d1HJOst1/3UrLeOemnNe3/1OfPyK2N+NOe\n5La2T/pUjzVLjkrWr5m5LFk/efS23NovtuefnyBJF934lWT9I1fmT00e1XLv0hbfNKQfWRjKkf9W\nSXMGWX61u0/P/lUMPoDmUjH87v6IpE0N6AVAA9Xymf9CM3vGzJaY2fjCOgLQENWG/3uSDpc0XVKP\npG/lrWhmC8ys28y6d2pHlbsDULSqwu/uve6+2937JN0kKXcmSXfvdPcOd+9o1ahq+wRQsKrCb2bt\nAx7OlfRsMe0AaJSKl/Sa2R2STpR0gJmtl3S5pBPNbLokl7RO0pfr2COAOqg4zl+k4TzOv+PUT+bW\nvnPDd5PbTmtNj2dX8kbf9mR93pf+Mre2T9eTNe27kpZPTEvW//fS/P/2q37v35Lbfnp0epDp7DVz\nk/W+z+d/x7T713vnAFbR4/wA9kKEHwiK8ANBEX4gKMIPBEX4gaAY6huiKU/kn5149Udqu7R04+63\nk/VTF38jWZ94w/C8tPWFzvzhU0l64TP/UtPzp362fMoXV9T03M2KoT4AFRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFBM0Z3Z/tncHyOSJC1u/06imr5kt9I4/tnnfz1Zn/jj4TmOX8nUG99K1o998aJkfdkF\nub8eJ0l66tPX59bm/smFyW1bH6rvpdDNgCM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8D3LZ5\nRrLe9uPHG9RJcxnR+2ayvu3Qccn6ka0jk/Vz1p2UW2vrXpPcdneyunfgyA8ERfiBoAg/EBThB4Ii\n/EBQhB8IivADQVUc5zezSZJuk/Q7kvokdbr7tWY2QdKdkiZLWifpLHd/o36t1lfbv6fH2h+9ev/c\n2uzR6evSO8asTdYfOWROsr5r/avJeplaxo5N1n/9hY/n1r6+aFly28+P25isP/x2W3rfCw/NrbW8\n+VRy2wiGcuTfJelid58m6XhJF5jZ0ZIWSupy9ymSurLHAIaJiuF39x53X5Hd3ypptaSDJZ0uaWm2\n2lJJZ9SrSQDF+0Cf+c1ssqQZkpZLOsjde6T+PxCSJhbdHID6GXL4zWycpLskfc3dt3yA7RaYWbeZ\nde/Ujmp6BFAHQwq/mbWqP/i3u/vd2eJeM2vP6u2SNgy2rbt3unuHu3e0Kn+ySwCNVTH8ZmaSbpG0\n2t2/PaB0n6T52f35ku4tvj0A9TKUS3pnSTpH0kozezpbtkjSYkk/NLNzJb0s6cz6tNgcFl/0xdxa\n23W3JLc9oe2dZP1vPvvRZH3iza8n674z/fwpLWPGJOu7ZxyZrB9/Q3qIdNEB1+XW3vJ03yetmpes\nj/nr9DvJllUM56VUDL+7Pyopb77v2cW2A6BROMMPCIrwA0ERfiAowg8ERfiBoAg/EJS5e8N2tp9N\n8ONs7xsdHHHggcn6Vx77RbJ+ypityfrFPccn6y9vm5Csp3SMfylZv/TDzyXrPbvTlzOfuWp+bq3t\nmvHJbUf+pDtZx/st9y5t8U15Q/PvwpEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8B3pnzyWT9\nza+mx/k/N3llsr5qS3tu7c/bH01ue9mq9O+uvtmzX7I+9cIVybrv2pWso1iM8wOoiPADQRF+ICjC\nDwRF+IGgCD8QFOEHgmKcH9iLMM4PoCLCDwRF+IGgCD8QFOEHgiL8QFCEHwiqYvjNbJKZPWxmq81s\nlZn9Vbb8CjN71cyezv6dWv92ARRlnyGss0vSxe6+wsz2lfSkmT2Y1a5296vq1x6AeqkYfnfvkdST\n3d9qZqslHVzvxgDU1wf6zG9mkyXNkLQ8W3ShmT1jZkvMbNC5l8xsgZl1m1n3Tu2oqVkAxRly+M1s\nnKS7JH3N3bdI+p6kwyVNV/87g28Ntp27d7p7h7t3tGpUAS0DKMKQwm9mreoP/u3ufrckuXuvu+92\n9z5JN0maWb82ARRtKN/2m6RbJK12928PWD7wJ2PnSnq2+PYA1MtQvu2fJekcSSvN7Ols2SJJ88xs\nuiSXtE7Sl+vSIYC6GMq3/Y9KGuz64PuLbwdAo3CGHxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4Ii/EBQhB8IivADQRF+IKiGTtFtZq9LemnAogMkbWxYAx9Ms/bWrH1J9FatIns71N0P\nHMqKDQ3/+3Zu1u3uHaU1kNCsvTVrXxK9Vaus3njbDwRF+IGgyg5/Z8n7T2nW3pq1L4neqlVKb6V+\n5gdQnrKP/ABKUkr4zWyOmf2Pma0xs4Vl9JDHzNaZ2cps5uHukntZYmYbzOzZAcsmmNmDZvZidjvo\nNGkl9dYUMzcnZpYu9bVrthmvG/6238xGSHpB0kmS1kt6QtI8d3+uoY3kMLN1kjrcvfQxYTM7QdJv\nJN3m7sdky66UtMndF2d/OMe7+982SW9XSPpN2TM3ZxPKtA+cWVrSGZK+pBJfu0RfZ6mE162MI/9M\nSWvcfa27vyNpmaTTS+ij6bn7I5I2vWfx6ZKWZveXqv9/nobL6a0puHuPu6/I7m+VtGdm6VJfu0Rf\npSgj/AdLemXA4/Vqrim/XdIDZvakmS0ou5lBHJRNm75n+vSJJffzXhVnbm6k98ws3TSvXTUzXhet\njPAPNvtPMw05zHL3YyWdIumC7O0thmZIMzc3yiAzSzeFame8LloZ4V8vadKAx4dIeq2EPgbl7q9l\ntxsk3aPmm324d88kqdnthpL7+a1mmrl5sJml1QSvXTPNeF1G+J+QNMXMDjOzkZLOlnRfCX28j5mN\nzb6IkZmNlXSymm/24fskzc/uz5d0b4m9vEuzzNycN7O0Sn7tmm3G61JO8smGMq6RNELSEnf/x4Y3\nMQgz+131H+2l/klMf1Bmb2Z2h6QT1X/VV6+kyyX9SNIPJX1U0suSznT3hn/xltPbiep/6/rbmZv3\nfMZucG+fkvRzSSsl9WWLF6n/83Vpr12ir3kq4XXjDD8gKM7wA4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8Q1P8D4IVrimsihu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbb3a62908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time  #fast learn\n",
    "NUMBER_TO_TEST = 1234  #from 0 to 9999    1234 was error at linear models\n",
    "\n",
    "with tf.Session () as sess:\n",
    "    sess.run(tf.global_variables_initializer ())\n",
    "    for i in range (NUM_STEPS):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x , y_true: batch_y})\n",
    "    ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "    \n",
    "    #My code\n",
    "    output_pr = sess.run(y_pred, feed_dict={x: data.test.images})\n",
    "    output_pos = sess.run(tf.argmax(y_pred, 1), feed_dict={x: data.test.images})\n",
    "    print(output_pr[NUMBER_TO_TEST])\n",
    "    print(output_pos[NUMBER_TO_TEST])\n",
    "    #My code ended\n",
    "    \n",
    "print (\"Accuracy {:.4}% \".format(ans * 100))\n",
    "   \n",
    "    \n",
    "#My code \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plotData = data.test.images[NUMBER_TO_TEST]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(data.test.labels[NUMBER_TO_TEST])\n",
    "#My code ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same but another amount of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = 200\n",
    "L2 = 100\n",
    "L3 = 60\n",
    "L4 = 30\n",
    "L5 = 10\n",
    "\n",
    "DATA_DIR = 'tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-171b22a893cf>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-3-171b22a893cf>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR, one_hot = True)\n",
    "x = tf.placeholder(tf.float32 , [None, 784])\n",
    "l1 = tf.layers.dense(x, L1, activation = tf.nn.relu, use_bias = True)\n",
    "l2 = tf.layers.dense(l1, L2, activation = tf.nn.relu, use_bias = True)\n",
    "l3 = tf.layers.dense(l2, L3, activation = tf.nn.relu, use_bias = True)\n",
    "l4 = tf.layers.dense(l3, L4, activation = tf.nn.relu, use_bias = True)\n",
    "y_pred = tf.layers.dense(l4, L5, activation = tf.nn.sigmoid, use_bias = True)\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.85% \n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session () as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range (NUM_STEPS):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x, y_true : batch_y})\n",
    "        ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "print(\"Accuracy: {:.4}% \".format(ans*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52113193 0.55026686 0.70388913 2.9337268  0.         1.916382\n",
      " 0.5922773  0.         6.069199   0.210646  ]\n",
      "8\n",
      "Accuracy 96.13% \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGgCD8Q1P8D4IVrimsihu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e997ef0ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUMBER_TO_TEST = 1234  #from 0 to 9999    1234 was error at linear models\n",
    "\n",
    "with tf.Session () as sess:\n",
    "    sess.run(tf.global_variables_initializer ())\n",
    "    for i in range (NUM_STEPS):\n",
    "        batch_x, batch_y = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict = {x: batch_x , y_true: batch_y})\n",
    "    ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "    \n",
    "    #My code\n",
    "    output_pr = sess.run(y_pred, feed_dict={x: data.test.images})\n",
    "    output_pos = sess.run(tf.argmax(y_pred, 1), feed_dict={x: data.test.images})\n",
    "    print(output_pr[NUMBER_TO_TEST])\n",
    "    print(output_pos[NUMBER_TO_TEST])\n",
    "    #My code ended\n",
    "    \n",
    "print (\"Accuracy {:.4}% \".format(ans * 100))\n",
    "   \n",
    "    \n",
    "#My code \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plotData = data.test.images[NUMBER_TO_TEST]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(data.test.labels[NUMBER_TO_TEST])\n",
    "#My code ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
